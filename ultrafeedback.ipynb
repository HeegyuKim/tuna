{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"openbmb/UltraFeedback\", split=\"train\")\n",
    "ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = ds.train_test_split(test_size=1000, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 32/32 [00:05<00:00,  6.09ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 32/32 [00:05<00:00,  6.10ba/s]s/it]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 2/2 [00:20<00:00, 10.13s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00,  6.05ba/s]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:00<00:00,  1.24it/s]\n"
     ]
    }
   ],
   "source": [
    "dd.push_to_hub(\"heegyu/UltraFeedback-split\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Max-margin dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dd = DatasetDict()\n",
    "for k in dd:\n",
    "    ds = dd[k]\n",
    "    items = []\n",
    "\n",
    "    for item in ds:\n",
    "        completions = sorted(item[\"completions\"], key=lambda x: x[\"overall_score\"], reverse=True)\n",
    "        if len(completions) < 2:\n",
    "            continue\n",
    "        \n",
    "        chosen, rejected = completions[0], completions[-1]\n",
    "\n",
    "        items.append({\n",
    "            \"instruction\": item[\"instruction\"],\n",
    "            \"chosen\": chosen[\"response\"],\n",
    "            \"chosen_critique\": chosen[\"critique\"],\n",
    "            \"chosen_score\": chosen[\"overall_score\"],\n",
    "            \"rejected\": rejected[\"response\"],\n",
    "            \"rejected_critique\": rejected[\"critique\"],\n",
    "            \"rejected_score\": rejected[\"overall_score\"],\n",
    "        })\n",
    "\n",
    "    new_dd[k] = Dataset.from_list(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['instruction', 'chosen', 'chosen_critique', 'chosen_score', 'rejected', 'rejected_critique', 'rejected_score'],\n",
      "        num_rows: 62966\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['instruction', 'chosen', 'chosen_critique', 'chosen_score', 'rejected', 'rejected_critique', 'rejected_score'],\n",
      "        num_rows: 1000\n",
      "    })\n",
      "})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 63/63 [00:01<00:00, 60.04ba/s]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:06<00:00,  6.14s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 52.77ba/s]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:00<00:00,  1.42it/s]\n"
     ]
    }
   ],
   "source": [
    "print(new_dd)\n",
    "# pprint(new_dd['train'][0])\n",
    "new_dd.push_to_hub(\"heegyu/Ultrafeedback-split-dpo-max-margin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Every Pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dd = DatasetDict()\n",
    "for k in dd:\n",
    "    ds = dd[k]\n",
    "    items = []\n",
    "\n",
    "    for item in ds:\n",
    "        completions = sorted(item[\"completions\"], key=lambda x: x[\"overall_score\"], reverse=True)\n",
    "        if len(completions) < 2:\n",
    "            continue\n",
    "        \n",
    "        for i, chosen in enumerate(completions[:-1]):\n",
    "            for rejected in completions[i + 1:]:\n",
    "                if abs(chosen[\"overall_score\"] - rejected[\"overall_score\"]) < 1.0:\n",
    "                    continue\n",
    "\n",
    "                items.append({\n",
    "                    \"instruction\": item[\"instruction\"],\n",
    "                    \"chosen\": chosen[\"response\"],\n",
    "                    \"chosen_critique\": chosen[\"critique\"],\n",
    "                    \"chosen_score\": chosen[\"overall_score\"],\n",
    "                    \"rejected\": rejected[\"response\"],\n",
    "                    \"rejected_critique\": rejected[\"critique\"],\n",
    "                    \"rejected_score\": rejected[\"overall_score\"],\n",
    "                })\n",
    "            chosen, rejected = completions[0], completions[-1]\n",
    "\n",
    "            items.append({\n",
    "                \"instruction\": item[\"instruction\"],\n",
    "                \"chosen\": chosen[\"response\"],\n",
    "                \"chosen_critique\": chosen[\"critique\"],\n",
    "                \"chosen_score\": chosen[\"overall_score\"],\n",
    "                \"rejected\": rejected[\"response\"],\n",
    "                \"rejected_critique\": rejected[\"critique\"],\n",
    "                \"rejected_score\": rejected[\"overall_score\"],\n",
    "            })\n",
    "\n",
    "    new_dd[k] = Dataset.from_list(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['instruction', 'chosen', 'chosen_critique', 'chosen_score', 'rejected', 'rejected_critique', 'rejected_score'],\n",
      "        num_rows: 436176\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['instruction', 'chosen', 'chosen_critique', 'chosen_score', 'rejected', 'rejected_critique', 'rejected_score'],\n",
      "        num_rows: 6892\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(new_dd)\n",
    "# pprint(new_dd['train'][0])\n",
    "# new_dd.push_to_hub(\"heegyu/Ultrafeedback-split-dpo-max-margin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Critique 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dd = DatasetDict()\n",
    "for k in dd:\n",
    "    ds = dd[k]\n",
    "    items = []\n",
    "\n",
    "    for item in ds:\n",
    "        for response in item[\"completions\"]:\n",
    "            items.append({\n",
    "                \"instruction\": item[\"instruction\"],\n",
    "                \"output\": response[\"response\"],\n",
    "                \"critique\": response[\"critique\"],\n",
    "                \"overall_score\": response[\"overall_score\"]\n",
    "            })\n",
    "\n",
    "    new_dd[k] = Dataset.from_list(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['instruction', 'output', 'critique', 'overall_score'],\n",
       "        num_rows: 251864\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['instruction', 'output', 'critique', 'overall_score'],\n",
       "        num_rows: 4000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 126/126 [00:00<00:00, 130.86ba/s]\n",
      "Creating parquet from Arrow format: 100%|██████████| 126/126 [00:00<00:00, 131.69ba/s]t]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 2/2 [00:13<00:00,  6.78s/it]\n",
      "Creating parquet from Arrow format: 100%|██████████| 4/4 [00:00<00:00, 122.60ba/s]\n",
      "Pushing dataset shards to the dataset hub: 100%|██████████| 1/1 [00:00<00:00,  1.46it/s]\n"
     ]
    }
   ],
   "source": [
    "new_dd.push_to_hub(\"heegyu/Ultrafeedback-split-critiques\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
